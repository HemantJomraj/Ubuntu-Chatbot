{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"New Chatbot.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"metadata":{"id":"F0yO3WXdd5oP","colab_type":"code","outputId":"8bb5db39-4057-4989-f049-ce468ca76c22","executionInfo":{"status":"ok","timestamp":1554780600837,"user_tz":-330,"elapsed":4958,"user":{"displayName":"Darshan Kakwani","photoUrl":"","userId":"06813604131485796128"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"cell_type":"code","source":["!pip install tensorflow==1.8"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow==1.8 in /usr/local/lib/python3.6/dist-packages (1.8.0)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (0.7.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (0.7.1)\n","Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (3.7.1)\n","Requirement already satisfied: tensorboard<1.9.0,>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (1.8.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (1.14.6)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (0.2.2)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (0.33.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (1.15.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (1.11.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (1.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow==1.8) (40.9.0)\n","Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8) (0.9999999)\n","Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8) (0.15.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8) (3.1)\n","Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8) (1.5.0)\n"],"name":"stdout"}]},{"metadata":{"id":"yPtfoBrreQpE","colab_type":"code","outputId":"731e912b-d8f7-4765-f388-179431b340cd","executionInfo":{"status":"ok","timestamp":1554780600841,"user_tz":-330,"elapsed":4916,"user":{"displayName":"Darshan Kakwani","photoUrl":"","userId":"06813604131485796128"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"m5qlT40feczg","colab_type":"code","colab":{}},"cell_type":"code","source":["  # udc_metrics\n","\n","  import tensorflow as tf\n","  import functools\n","  from tensorflow.contrib.learn.python.learn.metric_spec import MetricSpec\n","\n","\n","  def create_evaluation_metrics():\n","      eval_metrics = {}\n","      for k in [1, 2, 5, 10]:\n","          eval_metrics[\"recall_at_%d\" % k] = MetricSpec(metric_fn=functools.partial(\n","              tf.contrib.metrics.streaming_sparse_recall_at_k,\n","              k=k))\n","      return eval_metrics"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xeMW2XIoeizN","colab_type":"code","colab":{}},"cell_type":"code","source":["# udc_inputs\n","\n","import tensorflow as tf\n","\n","TEXT_FEATURE_SIZE = 160\n","\n","def get_feature_columns(mode):\n","  feature_columns = []\n","\n","  feature_columns.append(tf.contrib.layers.real_valued_column(\n","    column_name=\"context\", dimension=TEXT_FEATURE_SIZE, dtype=tf.int64))\n","  feature_columns.append(tf.contrib.layers.real_valued_column(\n","      column_name=\"context_len\", dimension=1, dtype=tf.int64))\n","  feature_columns.append(tf.contrib.layers.real_valued_column(\n","      column_name=\"utterance\", dimension=TEXT_FEATURE_SIZE, dtype=tf.int64))\n","  feature_columns.append(tf.contrib.layers.real_valued_column(\n","      column_name=\"utterance_len\", dimension=1, dtype=tf.int64))\n","\n","  if mode == tf.contrib.learn.ModeKeys.TRAIN:\n","    # During training we have a label feature\n","    feature_columns.append(tf.contrib.layers.real_valued_column(\n","      column_name=\"label\", dimension=1, dtype=tf.int64))\n","\n","  if mode == tf.contrib.learn.ModeKeys.EVAL:\n","    # During evaluation we have distractors\n","    for i in range(9):\n","      feature_columns.append(tf.contrib.layers.real_valued_column(\n","        column_name=\"distractor_{}\".format(i), dimension=TEXT_FEATURE_SIZE, dtype=tf.int64))\n","      feature_columns.append(tf.contrib.layers.real_valued_column(\n","        column_name=\"distractor_{}_len\".format(i), dimension=1, dtype=tf.int64))\n","\n","  return set(feature_columns)\n","\n","\n","def create_input_fn(mode, input_files, batch_size, num_epochs):\n","  def input_fn():\n","    features = tf.contrib.layers.create_feature_spec_for_parsing(\n","        get_feature_columns(mode))\n","\n","    feature_map = tf.contrib.learn.io.read_batch_features(\n","        file_pattern=input_files,\n","        batch_size=batch_size,\n","        features=features,\n","        reader=tf.TFRecordReader,\n","        randomize_input=True,\n","        num_epochs=num_epochs,\n","        queue_capacity=200000 + batch_size * 10,\n","        name=\"read_batch_features_{}\".format(mode))\n","\n","    # This is an ugly hack because of a current bug in tf.learn\n","    # During evaluation TF tries to restore the epoch variable which isn't defined during training\n","    # So we define the variable manually here\n","    if mode == tf.contrib.learn.ModeKeys.TRAIN:\n","      tf.get_variable(\n","        \"read_batch_features_eval/file_name_queue/limit_epochs/epochs\",\n","        initializer=tf.constant(0, dtype=tf.int64))\n","\n","    if mode == tf.contrib.learn.ModeKeys.TRAIN:\n","      target = feature_map.pop(\"label\")\n","    else:\n","      # In evaluation we have 10 classes (utterances).\n","      # The first one (index 0) is always the correct one\n","      target = tf.zeros([batch_size, 1], dtype=tf.int64)\n","    return feature_map, target\n","  return input_fn"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0WUT_oUcep7w","colab_type":"code","colab":{}},"cell_type":"code","source":["# udc_hparams\n","\n","import tensorflow as tf\n","from collections import namedtuple\n","\n","# Model Parameters\n","tf.flags.DEFINE_integer(\n","  \"vocab_size\",\n","  91620,\n","  \"The size of the vocabulary. Only change this if you changed the preprocessing\")\n","\n","# Model Parameters\n","tf.flags.DEFINE_integer(\"embedding_dim\", 100, \"Dimensionality of the embeddings\")\n","tf.flags.DEFINE_integer(\"rnn_dim\", 256, \"Dimensionality of the RNN cell\")\n","tf.flags.DEFINE_integer(\"max_context_len\", 160, \"Truncate contexts to this length\")\n","tf.flags.DEFINE_integer(\"max_utterance_len\", 80, \"Truncate utterance to this length\")\n","\n","# Pre-trained embeddings\n","tf.flags.DEFINE_string(\"glove_path\", None, \"Path to pre-trained Glove vectors\")\n","tf.flags.DEFINE_string(\"vocab_path\", None, \"Path to vocabulary.txt file\")\n","\n","# Training Parameters\n","tf.flags.DEFINE_float(\"learning_rate\", 0.001, \"Learning rate\")\n","tf.flags.DEFINE_integer(\"batch_size\", 128, \"Batch size during training\")\n","tf.flags.DEFINE_integer(\"eval_batch_size\", 16, \"Batch size during evaluation\")\n","tf.flags.DEFINE_string(\"optimizer\", \"Adam\", \"Optimizer Name (Adam, Adagrad, etc)\")\n","\n","FLAGS = tf.flags.FLAGS\n","\n","HParams = namedtuple(\n","  \"HParams\",\n","  [\n","    \"batch_size\",\n","    \"embedding_dim\",\n","    \"eval_batch_size\",\n","    \"learning_rate\",\n","    \"max_context_len\",\n","    \"max_utterance_len\",\n","    \"optimizer\",\n","    \"rnn_dim\",\n","    \"vocab_size\",\n","    \"glove_path\",\n","    \"vocab_path\"\n","  ])\n","\n","def create_hparams():\n","  return HParams(\n","    batch_size=FLAGS.batch_size,\n","    eval_batch_size=FLAGS.eval_batch_size,\n","    vocab_size=FLAGS.vocab_size,\n","    optimizer=FLAGS.optimizer,\n","    learning_rate=FLAGS.learning_rate,\n","    embedding_dim=FLAGS.embedding_dim,\n","    max_context_len=FLAGS.max_context_len,\n","    max_utterance_len=FLAGS.max_utterance_len,\n","    glove_path=FLAGS.glove_path,\n","    vocab_path=FLAGS.vocab_path,\n","    rnn_dim=FLAGS.rnn_dim)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qpHNd2vKeyf4","colab_type":"code","colab":{}},"cell_type":"code","source":["# udc_model\n","\n","import tensorflow as tf\n","import sys\n","\n","def get_id_feature(features, key, len_key, max_len):\n","  ids = features[key]\n","  ids_len = tf.squeeze(features[len_key], [1])\n","  ids_len = tf.minimum(ids_len, tf.constant(max_len, dtype=tf.int64))\n","  return ids, ids_len\n","\n","def create_train_op(loss, hparams):\n","  train_op = tf.contrib.layers.optimize_loss(\n","      loss=loss,\n","      global_step=tf.contrib.framework.get_global_step(),\n","      learning_rate=hparams.learning_rate,\n","      clip_gradients=10.0,\n","      optimizer=hparams.optimizer)\n","  return train_op\n","\n","\n","def create_model_fn(hparams, model_impl):\n","\n","  def model_fn(features, targets, mode):\n","    context, context_len = get_id_feature(\n","        features, \"context\", \"context_len\", hparams.max_context_len)\n","\n","    utterance, utterance_len = get_id_feature(\n","        features, \"utterance\", \"utterance_len\", hparams.max_utterance_len)\n","\n","    batch_size = targets.get_shape().as_list()[0]\n","\n","    if mode == tf.contrib.learn.ModeKeys.TRAIN:\n","      probs, loss = model_impl(\n","          hparams,\n","          mode,\n","          context,\n","          context_len,\n","          utterance,\n","          utterance_len,\n","          targets)\n","      train_op = create_train_op(loss, hparams)\n","      return probs, loss, train_op\n","\n","    if mode == tf.contrib.learn.ModeKeys.INFER:\n","      probs, loss = model_impl(\n","          hparams,\n","          mode,\n","          context,\n","          context_len,\n","          utterance,\n","          utterance_len,\n","          None)\n","      return probs, 0.0, None\n","\n","    if mode == tf.contrib.learn.ModeKeys.EVAL:\n","\n","      # We have 10 exampels per record, so we accumulate them\n","      all_contexts = [context]\n","      all_context_lens = [context_len]\n","      all_utterances = [utterance]\n","      all_utterance_lens = [utterance_len]\n","      all_targets = [tf.ones([batch_size, 1], dtype=tf.int64)]\n","\n","      for i in range(9):\n","        distractor, distractor_len = get_id_feature(features,\n","            \"distractor_{}\".format(i),\n","            \"distractor_{}_len\".format(i),\n","            hparams.max_utterance_len)\n","        all_contexts.append(context)\n","        all_context_lens.append(context_len)\n","        all_utterances.append(distractor)\n","        all_utterance_lens.append(distractor_len)\n","        all_targets.append(\n","          tf.zeros([batch_size, 1], dtype=tf.int64)\n","        )\n","\n","      probs, loss = model_impl(\n","          hparams,\n","          mode,\n","          tf.concat(all_contexts, 0),\n","          tf.concat(all_context_lens, 0),\n","          tf.concat(all_utterances, 0),\n","          tf.concat(all_utterance_lens, 0),\n","          tf.concat(all_targets, 0))\n","\n","      split_probs = tf.split(probs, 10, 0)\n","      shaped_probs = tf.concat(split_probs, 1)\n","\n","      # Add summaries\n","      tf.histogram(\"eval_correct_probs_hist\", split_probs[0])\n","      tf.scalar_summary(\"eval_correct_probs_average\", tf.reduce_mean(split_probs[0]))\n","      tf.histogram_summary(\"eval_incorrect_probs_hist\", split_probs[1])\n","      tf.scalar_summary(\"eval_incorrect_probs_average\", tf.reduce_mean(split_probs[1]))\n","\n","      return shaped_probs, loss, None\n","\n","  return model_fn"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1LU40m8Xfd5X","colab_type":"code","colab":{}},"cell_type":"code","source":["# helpers\n","\n","import array\n","import numpy as np\n","import tensorflow as tf\n","from collections import defaultdict\n","\n","def load_vocab(filename):\n","  vocab = None\n","  with open(filename) as f:\n","    vocab = f.read().splitlines()\n","  dct = defaultdict(int)\n","  for idx, word in enumerate(vocab):\n","    dct[word] = idx\n","  return [vocab, dct]\n","\n","def load_glove_vectors(filename, vocab):\n","  \"\"\"\n","  Load glove vectors from a .txt file.\n","  Optionally limit the vocabulary to save memory. `vocab` should be a set.\n","  \"\"\"\n","  dct = {}\n","  vectors = array.array('d')\n","  current_idx = 0\n","  with open(filename, \"r\", encoding=\"utf-8\") as f:\n","    for _, line in enumerate(f):\n","      tokens = line.split(\" \")\n","      word = tokens[0]\n","      entries = tokens[1:]\n","      if not vocab or word in vocab:\n","        dct[word] = current_idx\n","        vectors.extend(float(x) for x in entries)\n","        current_idx += 1\n","    word_dim = len(entries)\n","    num_vectors = len(dct)\n","    tf.logging.info(\"Found {} out of {} vectors in Glove\".format(num_vectors, len(vocab)))\n","    return [np.array(vectors).reshape(num_vectors, word_dim), dct]\n","\n","\n","def build_initial_embedding_matrix(vocab_dict, glove_dict, glove_vectors, embedding_dim):\n","  initial_embeddings = np.random.uniform(-0.25, 0.25, (len(vocab_dict), embedding_dim)).astype(\"float32\")\n","  for word, glove_word_idx in glove_dict.items():\n","    word_idx = vocab_dict.get(word)\n","    initial_embeddings[word_idx, :] = glove_vectors[glove_word_idx]\n","  return initial_embeddings"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hy4YEIQVfigz","colab_type":"code","colab":{}},"cell_type":"code","source":["# dual_encoder\n","\n","import tensorflow as tf\n","import numpy as np\n","\n","FLAGS = tf.flags.FLAGS\n","\n","def get_embeddings(hparams):\n","  if hparams.glove_path and hparams.vocab_path:\n","    tf.logging.info(\"Loading Glove embeddings...\")\n","    vocab_array, vocab_dict = helpers.load_vocab(hparams.vocab_path)\n","    glove_vectors, glove_dict = helpers.load_glove_vectors(hparams.glove_path, vocab=set(vocab_array))\n","    initializer = helpers.build_initial_embedding_matrix(vocab_dict, glove_dict, glove_vectors, hparams.embedding_dim)\n","  else:\n","    tf.logging.info(\"No glove/vocab path specificed, starting with random embeddings.\")\n","    initializer = tf.random_uniform_initializer(-0.25, 0.25)\n","\n","  return tf.get_variable(\n","    \"word_embeddings\",\n","    shape=[hparams.vocab_size, hparams.embedding_dim],\n","    initializer=initializer)\n","\n","\n","def dual_encoder_model(\n","    hparams,\n","    mode,\n","    context,\n","    context_len,\n","    utterance,\n","    utterance_len,\n","    targets):\n","\n","  # Initialize embedidngs randomly or with pre-trained vectors if available\n","  embeddings_W = get_embeddings(hparams)\n","\n","  # Embed the context and the utterance\n","  context_embedded = tf.nn.embedding_lookup(\n","      embeddings_W, context, name=\"embed_context\")\n","  utterance_embedded = tf.nn.embedding_lookup(\n","      embeddings_W, utterance, name=\"embed_utterance\")\n","\n","\n","  # Build the RNN\n","  with tf.variable_scope(\"rnn\") as vs:\n","    # We use an LSTM Cell\n","    cell = tf.contrib.rnn.BasicLSTMCell(\n","        hparams.rnn_dim,\n","        forget_bias=2.0,\n","        state_is_tuple=True)\n","\n","    # Run the utterance and context through the RNN\n","    rnn_outputs, rnn_states = tf.nn.dynamic_rnn(\n","        cell,\n","        tf.concat([context_embedded, utterance_embedded], 0),\n","        sequence_length=tf.concat([context_len, utterance_len], 0),\n","        dtype=tf.float32)\n","    encoding_context, encoding_utterance = tf.split(rnn_states.h, 2, 0)\n","\n","  with tf.variable_scope(\"prediction\") as vs:\n","    M = tf.get_variable(\"M\",\n","      shape=[hparams.rnn_dim, hparams.rnn_dim],\n","      initializer=tf.truncated_normal_initializer())\n","\n","    # \"Predict\" a  response: c * M\n","    generated_response = tf.matmul(encoding_context, M)\n","    generated_response = tf.expand_dims(generated_response, 2)\n","    encoding_utterance = tf.expand_dims(encoding_utterance, 2)\n","\n","    # Dot product between generated response and actual response\n","    # (c * M) * r\n","    logits = tf.matmul(generated_response, encoding_utterance, True)\n","    logits = tf.squeeze(logits, [2])\n","\n","    # Apply sigmoid to convert logits to probabilities\n","    probs = tf.sigmoid(logits)\n","\n","    if mode == tf.contrib.learn.ModeKeys.INFER:\n","      return probs, None\n","\n","    # Calculate the binary cross-entropy loss\n","    losses = tf.nn.sigmoid_cross_entropy_with_logits(logits = logits, labels = tf.to_float(targets))\n","\n","  # Mean loss across the batch of examples\n","  mean_loss = tf.reduce_mean(losses, name=\"mean_loss\")\n","  return probs, mean_loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LSRMwR0ae4QO","colab_type":"code","outputId":"9fefbf02-667d-45c0-f66f-a19b151510b2","executionInfo":{"status":"error","timestamp":1553703963621,"user_tz":-330,"elapsed":1235601,"user":{"displayName":"Darshan Kakwani","photoUrl":"","userId":"06813604131485796128"}},"colab":{"base_uri":"https://localhost:8080/","height":1057}},"cell_type":"code","source":["# udc_train\n","\n","import os\n","import time\n","import itertools\n","import tensorflow as tf\n","\n","tf.app.flags.DEFINE_string('f', '', 'kernel')\n","tf.app.flags.DEFINE_string(\"input_dir\", \"drive/My Drive/BE Project/New Chatbot/data\", \"Directory containing input data files 'train.tfrecords' and 'validation.tfrecords'\")\n","tf.app.flags.DEFINE_string(\"model_dir\", None, \"Directory to store model checkpoints (defaults to ./runs)\")\n","tf.app.flags.DEFINE_integer(\"loglevel\", 20, \"Tensorflow log level\")\n","tf.app.flags.DEFINE_integer(\"num_epochs\", None, \"Number of training Epochs. Defaults to indefinite.\")\n","tf.app.flags.DEFINE_integer(\"eval_every\", 1000, \"Evaluate after this many train steps\")\n","FLAGS = tf.app.flags.FLAGS\n","\n","TIMESTAMP = int(time.time())\n","\n","if FLAGS.model_dir:\n","  MODEL_DIR = FLAGS.model_dir\n","else:\n","  MODEL_DIR = os.path.abspath(os.path.join(\"drive/My Drive/BE Project/New Chatbot/runs\", str(TIMESTAMP)))\n","\n","TRAIN_FILE = os.path.abspath(os.path.join(FLAGS.input_dir, \"train.tfrecords\"))\n","VALIDATION_FILE = os.path.abspath(os.path.join(FLAGS.input_dir, \"validation.tfrecords\"))\n","\n","tf.logging.set_verbosity(FLAGS.loglevel)\n","\n","def main(unused_argv):\n","  hparams = create_hparams()\n","\n","  model_fn = create_model_fn(\n","    hparams,\n","    model_impl=dual_encoder_model)\n","\n","  estimator = tf.contrib.learn.Estimator(\n","    model_fn=model_fn,\n","    model_dir=MODEL_DIR,\n","    config=tf.contrib.learn.RunConfig())\n","\n","  input_fn_train = create_input_fn(\n","    mode=tf.contrib.learn.ModeKeys.TRAIN,\n","    input_files=[TRAIN_FILE],\n","    batch_size=hparams.batch_size,\n","    num_epochs=FLAGS.num_epochs)\n","\n","  input_fn_eval = create_input_fn(\n","    mode=tf.contrib.learn.ModeKeys.EVAL,\n","    input_files=[VALIDATION_FILE],\n","    batch_size=hparams.eval_batch_size,\n","    num_epochs=1)\n","\n","  eval_metrics = create_evaluation_metrics()\n","  \n","  eval_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n","        input_fn=input_fn_eval,\n","        every_n_steps=FLAGS.eval_every,\n","        metrics=eval_metrics)\n","\n","  estimator.fit(input_fn=input_fn_train, steps=None, monitors=[eval_monitor])\n","\n","if __name__ == \"__main__\":\n","  tf.app.run()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-9-cf2979004f4d>:37: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:1179: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n","INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa1e1ab1400>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_tf_config': gpu_options {\n","  per_process_gpu_memory_fraction: 1.0\n","}\n",", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/content/drive/My Drive/BE Project/New Chatbot/runs/1554780607'}\n","WARNING:tensorflow:From <ipython-input-3-e6fde66cd755>:12: MetricSpec.__init__ (from tensorflow.contrib.learn.python.learn.metric_spec) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.estimator.EstimatorSpec.eval_metric_ops.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:279: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n","Instructions for updating:\n","Monitors are deprecated. Please use tf.train.SessionRunHook.\n","WARNING:tensorflow:From <ipython-input-4-90c576b18bc4>:47: read_batch_features (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.data.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:833: read_keyed_batch_features (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.data.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:542: read_keyed_batch_examples (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.data.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:550: queue_parsed_features (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.data.\n","INFO:tensorflow:No glove/vocab path specificed, starting with random embeddings.\n","WARNING:tensorflow:From <ipython-input-6-af0f41c4f3f4>:14: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_global_step\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:1240: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 1 into /content/drive/My Drive/BE Project/New Chatbot/runs/1554780607/model.ckpt.\n","INFO:tensorflow:loss = 0.8880824, step = 1\n","INFO:tensorflow:global_step/sec: 0.229746\n","INFO:tensorflow:loss = 0.6841717, step = 101 (435.266 sec)\n","INFO:tensorflow:Saving checkpoints for 139 into /content/drive/My Drive/BE Project/New Chatbot/runs/1554780607/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.215652\n","INFO:tensorflow:loss = 0.6684376, step = 201 (463.712 sec)\n","INFO:tensorflow:Saving checkpoints for 265 into /content/drive/My Drive/BE Project/New Chatbot/runs/1554780607/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.2082\n","INFO:tensorflow:loss = 0.71934974, step = 301 (480.312 sec)\n","INFO:tensorflow:Saving checkpoints for 391 into /content/drive/My Drive/BE Project/New Chatbot/runs/1554780607/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.209844\n","INFO:tensorflow:loss = 0.66927916, step = 401 (476.542 sec)\n","INFO:tensorflow:global_step/sec: 0.215374\n","INFO:tensorflow:loss = 0.6461521, step = 501 (464.309 sec)\n","INFO:tensorflow:Saving checkpoints for 520 into /content/drive/My Drive/BE Project/New Chatbot/runs/1554780607/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.220402\n","INFO:tensorflow:loss = 0.68198115, step = 601 (453.715 sec)\n","INFO:tensorflow:Saving checkpoints for 654 into /content/drive/My Drive/BE Project/New Chatbot/runs/1554780607/model.ckpt.\n","INFO:tensorflow:global_step/sec: 0.220864\n","INFO:tensorflow:loss = 0.6874708, step = 701 (452.773 sec)\n"],"name":"stdout"}]}]}