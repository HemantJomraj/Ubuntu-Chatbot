{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"predict.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"metadata":{"id":"LXMCLBpV6XX9","colab_type":"code","outputId":"549794e1-6b30-4612-8cef-7095d73028cc","executionInfo":{"status":"ok","timestamp":1554819320288,"user_tz":-330,"elapsed":41374,"user":{"displayName":"Darshan Kakwani","photoUrl":"","userId":"06813604131485796128"}},"colab":{"base_uri":"https://localhost:8080/","height":731}},"cell_type":"code","source":["!pip install tensorflow==1.8"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/c6/d08f7c549330c2acc1b18b5c1f0f8d9d2af92f54d56861f331f372731671/tensorflow-1.8.0-cp36-cp36m-manylinux1_x86_64.whl (49.1MB)\n","\u001b[K    100% |████████████████████████████████| 49.1MB 717kB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (0.33.1)\n","Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (3.7.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (0.7.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (1.11.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (1.14.6)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (0.2.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (1.1.0)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (0.7.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (1.15.0)\n","Collecting tensorboard<1.9.0,>=1.8.0 (from tensorflow==1.8)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/a6/0ae6092b7542cfedba6b2a1c9b8dceaf278238c39484f3ba03b03f07803c/tensorboard-1.8.0-py3-none-any.whl (3.1MB)\n","\u001b[K    100% |████████████████████████████████| 3.1MB 9.6MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow==1.8) (40.9.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8) (3.1)\n","Collecting bleach==1.5.0 (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8)\n","  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n","Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8) (0.15.2)\n","Collecting html5lib==0.9999999 (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n","\u001b[K    100% |████████████████████████████████| 890kB 14.6MB/s \n","\u001b[?25hBuilding wheels for collected packages: html5lib\n","  Building wheel for html5lib (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n","Successfully built html5lib\n","\u001b[31mmagenta 0.3.19 has requirement tensorflow>=1.12.0, but you'll have tensorflow 1.8.0 which is incompatible.\u001b[0m\n","Installing collected packages: html5lib, bleach, tensorboard, tensorflow\n","  Found existing installation: html5lib 1.0.1\n","    Uninstalling html5lib-1.0.1:\n","      Successfully uninstalled html5lib-1.0.1\n","  Found existing installation: bleach 3.1.0\n","    Uninstalling bleach-3.1.0:\n","      Successfully uninstalled bleach-3.1.0\n","  Found existing installation: tensorboard 1.13.1\n","    Uninstalling tensorboard-1.13.1:\n","      Successfully uninstalled tensorboard-1.13.1\n","  Found existing installation: tensorflow 1.13.1\n","    Uninstalling tensorflow-1.13.1:\n","      Successfully uninstalled tensorflow-1.13.1\n","Successfully installed bleach-1.5.0 html5lib-0.9999999 tensorboard-1.8.0 tensorflow-1.8.0\n"],"name":"stdout"}]},{"metadata":{"id":"1HRsN7v16nor","colab_type":"code","outputId":"dc2e4165-976e-4161-e0e5-2f1f65cf6d55","executionInfo":{"status":"ok","timestamp":1554819344263,"user_tz":-330,"elapsed":64455,"user":{"displayName":"Darshan Kakwani","photoUrl":"","userId":"06813604131485796128"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"metadata":{"id":"yVvWaev26tb8","colab_type":"code","colab":{}},"cell_type":"code","source":["# udc_metrics\n","\n","import tensorflow as tf\n","import functools\n","from tensorflow.contrib.learn.python.learn.metric_spec import MetricSpec\n","\n","\n","def create_evaluation_metrics():\n","    eval_metrics = {}\n","    for k in [1, 2, 5, 10]:\n","        eval_metrics[\"recall_at_%d\" % k] = MetricSpec(metric_fn=functools.partial(\n","            tf.contrib.metrics.streaming_sparse_recall_at_k,\n","            k=k))\n","    return eval_metrics"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ImAkq4Gm6xtL","colab_type":"code","colab":{}},"cell_type":"code","source":["# udc_inputs\n","\n","import tensorflow as tf\n","\n","TEXT_FEATURE_SIZE = 160\n","\n","def get_feature_columns(mode):\n","  feature_columns = []\n","\n","  feature_columns.append(tf.contrib.layers.real_valued_column(\n","    column_name=\"context\", dimension=TEXT_FEATURE_SIZE, dtype=tf.int64))\n","  feature_columns.append(tf.contrib.layers.real_valued_column(\n","      column_name=\"context_len\", dimension=1, dtype=tf.int64))\n","  feature_columns.append(tf.contrib.layers.real_valued_column(\n","      column_name=\"utterance\", dimension=TEXT_FEATURE_SIZE, dtype=tf.int64))\n","  feature_columns.append(tf.contrib.layers.real_valued_column(\n","      column_name=\"utterance_len\", dimension=1, dtype=tf.int64))\n","\n","  if mode == tf.contrib.learn.ModeKeys.TRAIN:\n","    # During training we have a label feature\n","    feature_columns.append(tf.contrib.layers.real_valued_column(\n","      column_name=\"label\", dimension=1, dtype=tf.int64))\n","\n","  if mode == tf.contrib.learn.ModeKeys.EVAL:\n","    # During evaluation we have distractors\n","    for i in range(9):\n","      feature_columns.append(tf.contrib.layers.real_valued_column(\n","        column_name=\"distractor_{}\".format(i), dimension=TEXT_FEATURE_SIZE, dtype=tf.int64))\n","      feature_columns.append(tf.contrib.layers.real_valued_column(\n","        column_name=\"distractor_{}_len\".format(i), dimension=1, dtype=tf.int64))\n","\n","  return set(feature_columns)\n","\n","\n","def create_input_fn(mode, input_files, batch_size, num_epochs):\n","  def input_fn():\n","    features = tf.contrib.layers.create_feature_spec_for_parsing(\n","        get_feature_columns(mode))\n","\n","    feature_map = tf.contrib.learn.io.read_batch_features(\n","        file_pattern=input_files,\n","        batch_size=batch_size,\n","        features=features,\n","        reader=tf.TFRecordReader,\n","        randomize_input=True,\n","        num_epochs=num_epochs,\n","        queue_capacity=200000 + batch_size * 10,\n","        name=\"read_batch_features_{}\".format(mode))\n","\n","    # This is an ugly hack because of a current bug in tf.learn\n","    # During evaluation TF tries to restore the epoch variable which isn't defined during training\n","    # So we define the variable manually here\n","    if mode == tf.contrib.learn.ModeKeys.TRAIN:\n","      tf.get_variable(\n","        \"read_batch_features_eval/file_name_queue/limit_epochs/epochs\",\n","        initializer=tf.constant(0, dtype=tf.int64))\n","\n","    if mode == tf.contrib.learn.ModeKeys.TRAIN:\n","      target = feature_map.pop(\"label\")\n","    else:\n","      # In evaluation we have 10 classes (utterances).\n","      # The first one (index 0) is always the correct one\n","      target = tf.zeros([batch_size, 1], dtype=tf.int64)\n","    return feature_map, target\n","  return input_fn\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_E9khBnv63H1","colab_type":"code","colab":{}},"cell_type":"code","source":["# udc_hparams\n","\n","import tensorflow as tf\n","from collections import namedtuple\n","\n","# Model Parameters\n","tf.flags.DEFINE_integer(\n","  \"vocab_size\",\n","  91620,\n","  \"The size of the vocabulary. Only change this if you changed the preprocessing\")\n","\n","# Model Parameters\n","tf.flags.DEFINE_integer(\"embedding_dim\", 100, \"Dimensionality of the embeddings\")\n","tf.flags.DEFINE_integer(\"rnn_dim\", 256, \"Dimensionality of the RNN cell\")\n","tf.flags.DEFINE_integer(\"max_context_len\", 160, \"Truncate contexts to this length\")\n","tf.flags.DEFINE_integer(\"max_utterance_len\", 80, \"Truncate utterance to this length\")\n","\n","# Pre-trained embeddings\n","tf.flags.DEFINE_string(\"glove_path\", None, \"Path to pre-trained Glove vectors\")\n","tf.flags.DEFINE_string(\"vocab_path\", None, \"Path to vocabulary.txt file\")\n","\n","# Training Parameters\n","tf.flags.DEFINE_float(\"learning_rate\", 0.001, \"Learning rate\")\n","tf.flags.DEFINE_integer(\"batch_size\", 128, \"Batch size during training\")\n","tf.flags.DEFINE_integer(\"eval_batch_size\", 16, \"Batch size during evaluation\")\n","tf.flags.DEFINE_string(\"optimizer\", \"Adam\", \"Optimizer Name (Adam, Adagrad, etc)\")\n","\n","FLAGS = tf.flags.FLAGS\n","\n","HParams = namedtuple(\n","  \"HParams\",\n","  [\n","    \"batch_size\",\n","    \"embedding_dim\",\n","    \"eval_batch_size\",\n","    \"learning_rate\",\n","    \"max_context_len\",\n","    \"max_utterance_len\",\n","    \"optimizer\",\n","    \"rnn_dim\",\n","    \"vocab_size\",\n","    \"glove_path\",\n","    \"vocab_path\"\n","  ])\n","\n","def create_hparams():\n","  return HParams(\n","    batch_size=FLAGS.batch_size,\n","    eval_batch_size=FLAGS.eval_batch_size,\n","    vocab_size=FLAGS.vocab_size,\n","    optimizer=FLAGS.optimizer,\n","    learning_rate=FLAGS.learning_rate,\n","    embedding_dim=FLAGS.embedding_dim,\n","    max_context_len=FLAGS.max_context_len,\n","    max_utterance_len=FLAGS.max_utterance_len,\n","    glove_path=FLAGS.glove_path,\n","    vocab_path=FLAGS.vocab_path,\n","    rnn_dim=FLAGS.rnn_dim)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D8EHeC7D679T","colab_type":"code","colab":{}},"cell_type":"code","source":["# udc_model\n","\n","import tensorflow as tf\n","import sys\n","\n","def get_id_feature(features, key, len_key, max_len):\n","  ids = features[key]\n","  ids_len = tf.squeeze(features[len_key], [1])\n","  ids_len = tf.minimum(ids_len, tf.constant(max_len, dtype=tf.int64))\n","  return ids, ids_len\n","\n","def create_train_op(loss, hparams):\n","  train_op = tf.contrib.layers.optimize_loss(\n","      loss=loss,\n","      global_step=tf.contrib.framework.get_global_step(),\n","      learning_rate=hparams.learning_rate,\n","      clip_gradients=10.0,\n","      optimizer=hparams.optimizer)\n","  return train_op\n","\n","\n","def create_model_fn(hparams, model_impl):\n","\n","  def model_fn(features, targets, mode):\n","    context, context_len = get_id_feature(\n","        features, \"context\", \"context_len\", hparams.max_context_len)\n","\n","    utterance, utterance_len = get_id_feature(\n","        features, \"utterance\", \"utterance_len\", hparams.max_utterance_len)\n","\n","    if mode == tf.contrib.learn.ModeKeys.EVAL:\n","      _____batch_size = targets.get_shape().as_list()[0]\n","\n","    if mode == tf.contrib.learn.ModeKeys.TRAIN:\n","      probs, loss = model_impl(\n","          hparams,\n","          mode,\n","          context,\n","          context_len,\n","          utterance,\n","          utterance_len,\n","          targets)\n","      train_op = create_train_op(loss, hparams)\n","      return probs, loss, train_op\n","\n","    if mode == tf.contrib.learn.ModeKeys.INFER:\n","      probs, loss = model_impl(\n","          hparams,\n","          mode,\n","          context,\n","          context_len,\n","          utterance,\n","          utterance_len,\n","          None)\n","      return probs, 0.0, None\n","\n","    if mode == tf.contrib.learn.ModeKeys.EVAL:\n","\n","      # We have 10 exampels per record, so we accumulate them\n","      all_contexts = [context]\n","      all_context_lens = [context_len]\n","      all_utterances = [utterance]\n","      all_utterance_lens = [utterance_len]\n","      all_targets = [tf.ones([batch_size, 1], dtype=tf.int64)]\n","\n","      for i in range(9):\n","        distractor, distractor_len = get_id_feature(features,\n","            \"distractor_{}\".format(i),\n","            \"distractor_{}_len\".format(i),\n","            hparams.max_utterance_len)\n","        all_contexts.append(context)\n","        all_context_lens.append(context_len)\n","        all_utterances.append(distractor)\n","        all_utterance_lens.append(distractor_len)\n","        all_targets.append(\n","          tf.zeros([batch_size, 1], dtype=tf.int64)\n","        )\n","\n","      probs, loss = model_impl(\n","          hparams,\n","          mode,\n","          tf.concat(0, all_contexts),\n","          tf.concat(0, all_context_lens),\n","          tf.concat(0, all_utterances),\n","          tf.concat(0, all_utterance_lens),\n","          tf.concat(0, all_targets))\n","\n","      split_probs = tf.split(0, 10, probs)\n","      shaped_probs = tf.concat(1, split_probs)\n","\n","      # Add summaries\n","      tf.histogram_summary(\"eval_correct_probs_hist\", split_probs[0])\n","      tf.scalar_summary(\"eval_correct_probs_average\", tf.reduce_mean(split_probs[0]))\n","      tf.histogram_summary(\"eval_incorrect_probs_hist\", split_probs[1])\n","      tf.scalar_summary(\"eval_incorrect_probs_average\", tf.reduce_mean(split_probs[1]))\n","\n","      return shaped_probs, loss, None\n","\n","  return model_fn"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iI6Rv54q6-cG","colab_type":"code","colab":{}},"cell_type":"code","source":["# helpers\n","\n","import array\n","import numpy as np\n","import tensorflow as tf\n","from collections import defaultdict\n","\n","def load_vocab(filename):\n","  vocab = None\n","  with open(filename) as f:\n","    vocab = f.read().splitlines()\n","  dct = defaultdict(int)\n","  for idx, word in enumerate(vocab):\n","    dct[word] = idx\n","  return [vocab, dct]\n","\n","def load_glove_vectors(filename, vocab):\n","  \"\"\"\n","  Load glove vectors from a .txt file.\n","  Optionally limit the vocabulary to save memory. `vocab` should be a set.\n","  \"\"\"\n","  dct = {}\n","  vectors = array.array('d')\n","  current_idx = 0\n","  with open(filename, \"r\", encoding=\"utf-8\") as f:\n","    for _, line in enumerate(f):\n","      tokens = line.split(\" \")\n","      word = tokens[0]\n","      entries = tokens[1:]\n","      if not vocab or word in vocab:\n","        dct[word] = current_idx\n","        vectors.extend(float(x) for x in entries)\n","        current_idx += 1\n","    word_dim = len(entries)\n","    num_vectors = len(dct)\n","    tf.logging.info(\"Found {} out of {} vectors in Glove\".format(num_vectors, len(vocab)))\n","    return [np.array(vectors).reshape(num_vectors, word_dim), dct]\n","\n","\n","def build_initial_embedding_matrix(vocab_dict, glove_dict, glove_vectors, embedding_dim):\n","  initial_embeddings = np.random.uniform(-0.25, 0.25, (len(vocab_dict), embedding_dim)).astype(\"float32\")\n","  for word, glove_word_idx in glove_dict.items():\n","    word_idx = vocab_dict.get(word)\n","    initial_embeddings[word_idx, :] = glove_vectors[glove_word_idx]\n","  return initial_embeddings"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pIJYu1kv7B1N","colab_type":"code","colab":{}},"cell_type":"code","source":["# dual_encoder\n","\n","import tensorflow as tf\n","import numpy as np\n","\n","FLAGS = tf.flags.FLAGS\n","\n","def get_embeddings(hparams):\n","  if hparams.glove_path and hparams.vocab_path:\n","    tf.logging.info(\"Loading Glove embeddings...\")\n","    vocab_array, vocab_dict = helpers.load_vocab(hparams.vocab_path)\n","    glove_vectors, glove_dict = helpers.load_glove_vectors(hparams.glove_path, vocab=set(vocab_array))\n","    initializer = helpers.build_initial_embedding_matrix(vocab_dict, glove_dict, glove_vectors, hparams.embedding_dim)\n","  else:\n","    tf.logging.info(\"No glove/vocab path specificed, starting with random embeddings.\")\n","    initializer = tf.random_uniform_initializer(-0.25, 0.25)\n","\n","  return tf.get_variable(\n","    \"word_embeddings\",\n","    shape=[hparams.vocab_size, hparams.embedding_dim],\n","    initializer=initializer)\n","\n","\n","def dual_encoder_model(\n","    hparams,\n","    mode,\n","    context,\n","    context_len,\n","    utterance,\n","    utterance_len,\n","    targets):\n","\n","  # Initialize embedidngs randomly or with pre-trained vectors if available\n","  embeddings_W = get_embeddings(hparams)\n","\n","  # Embed the context and the utterance\n","  context_embedded = tf.nn.embedding_lookup(\n","      embeddings_W, context, name=\"embed_context\")\n","  utterance_embedded = tf.nn.embedding_lookup(\n","      embeddings_W, utterance, name=\"embed_utterance\")\n","\n","\n","  # Build the RNN\n","  with tf.variable_scope(\"rnn\") as vs:\n","    # We use an LSTM Cell\n","    cell = tf.contrib.rnn.BasicLSTMCell(\n","        hparams.rnn_dim,\n","        forget_bias=2.0,\n","        state_is_tuple=True)\n","\n","    # Run the utterance and context through the RNN\n","    rnn_outputs, rnn_states = tf.nn.dynamic_rnn(\n","        cell,\n","        tf.concat([context_embedded, utterance_embedded], 0),\n","        sequence_length=tf.concat([context_len, utterance_len], 0),\n","        dtype=tf.float32)\n","    encoding_context, encoding_utterance = tf.split(rnn_states.h, 2, 0)\n","\n","  with tf.variable_scope(\"prediction\") as vs:\n","    M = tf.get_variable(\"M\",\n","      shape=[hparams.rnn_dim, hparams.rnn_dim],\n","      initializer=tf.truncated_normal_initializer())\n","\n","    # \"Predict\" a  response: c * M\n","    generated_response = tf.matmul(encoding_context, M)\n","    generated_response = tf.expand_dims(generated_response, 2)\n","    encoding_utterance = tf.expand_dims(encoding_utterance, 2)\n","\n","    # Dot product between generated response and actual response\n","    # (c * M) * r\n","    logits = tf.matmul(generated_response, encoding_utterance, True)\n","    logits = tf.squeeze(logits, [2])\n","\n","    # Apply sigmoid to convert logits to probabilities\n","    probs = tf.sigmoid(logits)\n","\n","    if mode == tf.contrib.learn.ModeKeys.INFER:\n","      return probs, None\n","\n","    # Calculate the binary cross-entropy loss\n","    losses = tf.nn.sigmoid_cross_entropy_with_logits(logits = logits, labels = tf.to_float(targets))\n","\n","  # Mean loss across the batch of examples\n","  mean_loss = tf.reduce_mean(losses, name=\"mean_loss\")\n","  return probs, mean_loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"R6edPSgmMDaR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"0456093e-b2f1-4184-9ca7-3d7054ce28ac","executionInfo":{"status":"ok","timestamp":1554819425494,"user_tz":-330,"elapsed":1253,"user":{"displayName":"Darshan Kakwani","photoUrl":"","userId":"06813604131485796128"}}},"cell_type":"code","source":["import csv\n","\n","POTENTIAL_RESPONSES_2 = []\n","count = 0\n","with open('drive/My Drive/BE Project/New Chatbot/data/train.csv', 'r') as csvFile:\n","    reader = csv.reader(csvFile)\n","    for row in reader:\n","      if row[2] == '1':\n","        POTENTIAL_RESPONSES_2.insert(-1, row[1])\n","        count += 1\n","        if count == 100:\n","          break\n","csvFile.close()\n","print(len(POTENTIAL_RESPONSES_2))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["100\n"],"name":"stdout"}]},{"metadata":{"id":"7dtRkXlU7ImT","colab_type":"code","outputId":"1ebe47d9-3f15-4cbd-b733-a1de344a0711","executionInfo":{"status":"error","timestamp":1554819524887,"user_tz":-330,"elapsed":95632,"user":{"displayName":"Darshan Kakwani","photoUrl":"","userId":"06813604131485796128"}},"colab":{"base_uri":"https://localhost:8080/","height":1033}},"cell_type":"code","source":["import os\n","import time\n","import itertools\n","import sys\n","import numpy as np\n","import tensorflow as tf\n","tf.logging.set_verbosity(tf.logging.ERROR)\n","\n","tf.app.flags.DEFINE_string('f', '', 'kernel')\n","tf.app.flags.DEFINE_string(\"model_dir\", \"drive/My Drive/BE Project/New Chatbot/runs/1554744310\", \"Directory to load model checkpoints from\")\n","tf.app.flags.DEFINE_string(\"vocab_processor_file\", \"drive/My Drive/BE Project/New Chatbot/data/vocab_processor.bin\", \"Saved vocabulary processor file\")\n","FLAGS = tf.app.flags.FLAGS\n","\n","if not FLAGS.model_dir:\n","  print(\"You must specify a model directory\")\n","  sys.exit(1)\n","\n","def tokenizer_fn(iterator):\n","  return (x.split(\" \") for x in iterator)\n","\n","# Load vocabulary\n","vp = tf.contrib.learn.preprocessing.VocabularyProcessor.restore(\n","  FLAGS.vocab_processor_file)\n","\n","while(True):\n","  # Load your own data here\n","  INPUT_CONTEXT = input(\"You: \")\n","  POTENTIAL_RESPONSES = [\"Tilde(~)\",\n","                         \"The pwd command\", \n","                         \"The ls command\", \n","                         \"The cd command\",\n","                         \"The cp command\"]\n","  # hoem directory: tilde\n","  # current directory: pwd\n","  # files in current directory: ls\n","  # change directories: cd\n","  # copy a file: cp\n","  def get_features(context, utterance):\n","    context_matrix = np.array(list(vp.transform([context])))\n","    utterance_matrix = np.array(list(vp.transform([utterance])))\n","    context_len = len(context.split(\" \"))\n","    utterance_len = len(utterance.split(\" \"))\n","    features = {\n","      \"context\": tf.convert_to_tensor(context_matrix, dtype=tf.int64),\n","      \"context_len\": tf.constant(context_len, shape=[1,1], dtype=tf.int64),\n","      \"utterance\": tf.convert_to_tensor(utterance_matrix, dtype=tf.int64),\n","      \"utterance_len\": tf.constant(utterance_len, shape=[1,1], dtype=tf.int64),\n","    }\n","    return features, None\n","\n","  if __name__ == \"__main__\":\n","    hparams = create_hparams()\n","    model_fn = create_model_fn(hparams, model_impl=dual_encoder_model)\n","    estimator1 = tf.contrib.learn.Estimator(model_fn=model_fn, model_dir=FLAGS.model_dir)\n","\n","    from tensorflow.contrib.learn.python.learn.estimators import *\n","    estimator._targets_info = tensor_signature.TensorSignature(tf.constant(0, shape=[1,1]))\n","\n","    print(\"Context: {}\".format(INPUT_CONTEXT))\n","    #for r in POTENTIAL_RESPONSES_2:\n","    #  prob = estimator1.predict(input_fn=lambda: get_features(INPUT_CONTEXT, r))\n","    #  print(\"{}: {:g}\".format(r, next(prob)[0]))\n","    prob_list = []\n","    for i in range(0, len(POTENTIAL_RESPONSES_2)):\n","      prob = estimator1.predict(input_fn=lambda: get_features(INPUT_CONTEXT, POTENTIAL_RESPONSES_2[i]))\n","      prob_list.insert(-1, next(prob)[0])\n","    print(prob_list)\n","    print(POTENTIAL_RESPONSES_2[prob_list.index(max(prob_list))])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["You: how does laptop detect work\n","Context: how does laptop detect work\n","[0.4268438, 0.5626225, 0.46422946, 0.45374373, 0.44335067, 0.47942716, 0.64201534, 0.38687623, 0.40360367, 0.49531564, 0.53210795, 0.41370806, 0.28347912, 0.539279, 0.3346349, 0.55758935, 0.56257904, 0.4895674, 0.62244684, 0.6904243, 0.40109602, 0.52910775, 0.5766688, 0.46508995, 0.38935953, 0.64018416, 0.5536698, 0.61112416, 0.8110194, 0.63836706, 0.56682014, 0.607037, 0.5578797, 0.5230195, 0.4731681, 0.61390734, 0.5482358, 0.69628966, 0.5230902, 0.6575317, 0.48788372, 0.58585685, 0.6320344, 0.39866802, 0.51758474, 0.46498045, 0.43953103, 0.5433472, 0.50820637, 0.4781213, 0.44573638, 0.6056085, 0.5698607, 0.6645258, 0.48923835, 0.44135776, 0.4263947, 0.5091824, 0.49576584, 0.52947855, 0.3666636, 0.56097674, 0.42159867, 0.38560835, 0.5631664, 0.53784907, 0.5056747, 0.39569005, 0.49320233, 0.68914974, 0.49278402, 0.4930935, 0.64914685, 0.4672756, 0.40831524, 0.5112291, 0.710876, 0.6057149, 0.65751797, 0.43779668, 0.39078215, 0.44905943, 0.7302859, 0.4850859, 0.50385475, 0.3809016, 0.4926029, 0.41358015, 0.48993385, 0.5211926, 0.6194242, 0.45289108, 0.49438697, 0.40346715, 0.31652805, 0.51072717, 0.3609056, 0.3971985, 0.4511612, 0.48944923]\n","let me check __eou__ the icon be a 48x48 png file , i ve not test with a svg one , but it should work __eou__\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-dffda911a377>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;31m# Load your own data here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0mINPUT_CONTEXT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m   POTENTIAL_RESPONSES = [\"Tilde(~)\",\n\u001b[1;32m     29\u001b[0m                          \u001b[0;34m\"The pwd command\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         )\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}